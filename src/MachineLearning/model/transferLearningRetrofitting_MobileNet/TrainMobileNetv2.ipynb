{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "303423ad",
      "metadata": {
        "id": "303423ad"
      },
      "source": [
        "# initialize the Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1a6c3c",
      "metadata": {
        "id": "da1a6c3c"
      },
      "source": [
        "src : https://towardsdatascience.com/10-minutes-to-building-a-binary-image-classifier-by-applying-transfer-learning-to-mobilenet-eab5a8719525 ; https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2 ; https://www.youtube.com/watch?v=w8Qx40tHeEM&ab_channel=SebastiaanMath%C3%B4t ; https://colab.research.google.com/drive/1XYAXOHiXNWqmKedCj1WRcJ6mGpr4aVC0?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7386de7d",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7386de7d",
        "outputId": "7c963d40-ac05-4641-d60c-9048f47d987c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install keras keras_applications keras_preprocessing Keras-Applications sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f485ec42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f485ec42",
        "outputId": "f4c4293b-0590-4c2f-e4f8-8a78ba0d0cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#store working directory\n",
        "!pwd\n",
        "!workingDir=$(pwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d506b166",
      "metadata": {
        "id": "d506b166"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "102b0bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "102b0bac",
        "outputId": "2d17def7-1bad-4e09-88d4-b927421010ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50073af2",
      "metadata": {
        "id": "50073af2"
      },
      "source": [
        "## Initialize the Machine Learning Modules Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa8ad47",
      "metadata": {
        "id": "9fa8ad47"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras.applications.mobilenet_v2 as MN2\n",
        "import numpy as np\n",
        "from imageio import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448d5999",
      "metadata": {
        "id": "448d5999"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import MobileNetV2 as MN2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefd1554",
      "metadata": {
        "id": "aefd1554"
      },
      "source": [
        "### Initiate the model of MN2 or mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3686c108",
      "metadata": {
        "id": "3686c108"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902758f7",
      "metadata": {
        "id": "902758f7"
      },
      "source": [
        "### The Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c8fce0cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "c8fce0cc",
        "outputId": "ad9dc7ad-df69-41bb-986d-0da11ffaf9ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-36ae68eb0ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#224, 224, 3 depending on the original model in this case imagenet on MN2 is 224 224 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "How about if we put the sandwich 0. MN2 1. Pooling MN2 2. Convolution?(for feature sharpening) 3. Dense sigmoid\n",
        "\"\"\"\n",
        "input_shape=(224, 224, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "model.add(MN2(include_top = False, weights=\"imagenet\", input_shape=input_shape))\n",
        "#224, 224, 3 depending on the original model in this case imagenet on MN2 is 224 224 3\n",
        "#model.add(Flatten(input_shape=input_shape))\n",
        "#model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "#model.add(tf.keras.layers.Reshape((100,100,1),input_shape=X.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3,3), activation = \"relu\", input_shape=input_shape))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "model.add(tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "#model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "#model.add(tf.keras.layers.Flatten())\n",
        "#model.add(Dense(units = 256, activation = 'sigmoid'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 30, activation = 'softmax'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "# set layers 0 to be untrainable\n",
        "model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1bdcc302",
      "metadata": {
        "id": "1bdcc302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ce82ca-458b-48f0-e0c6-7f590febc4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 128)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      73792     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 21632)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               11076096  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,172,449\n",
            "Trainable params: 11,168,865\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#after adding the layers of cheese combine it by compile it\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "#model.compile(optimizer=RMSprop(learning_rate=0.01), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca33e87b",
      "metadata": {
        "id": "ca33e87b"
      },
      "source": [
        "# Retrofitting Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8e3bf1",
      "metadata": {
        "id": "be8e3bf1"
      },
      "source": [
        "> We are going to use yoga_poses dataset that is originated from the tensorflow   !wget -O yoga_poses.zip http://download.tensorflow.org/data/pose_classification/yoga_poses.zip\n",
        "which includes 5 pose\n",
        "\n",
        "1. Chair\n",
        "2. Cobra\n",
        "3. Dog\n",
        "4. Tree\n",
        "5. Warrior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e301757",
      "metadata": {
        "scrolled": true,
        "id": "0e301757"
      },
      "outputs": [],
      "source": [
        "!pwd; apt install wget -y; rm -f yoga_poses.zip ; rm -rf train test; wget http://download.tensorflow.org/data/pose_classification/yoga_poses.zip; rm -rf trainingDataset; mkdir trainingDataset; mv yoga_poses.zip trainingDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77eeafef",
      "metadata": {
        "collapsed": true,
        "id": "77eeafef"
      },
      "outputs": [],
      "source": [
        "!pwd; ls; apt install zip -y; cd trainingDataset; unzip yoga_poses.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f2522fc",
      "metadata": {
        "id": "7f2522fc"
      },
      "outputs": [],
      "source": [
        "!cd ${workingDir} "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02932db1",
      "metadata": {
        "id": "02932db1"
      },
      "source": [
        "### set variable for the training path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953d3dbf",
      "metadata": {
        "scrolled": true,
        "id": "953d3dbf"
      },
      "outputs": [],
      "source": [
        "#/home/albertstarfield/Documents/FileSekolah13(TE)/bangkit_error/runtime/Motionful-Project-Bangkit2022/src/MachineLearning/model/transferLearningRetrofitting_MobileNet\n",
        "import os\n",
        "\n",
        "trainingPath = './trainingDataset/train/'\n",
        "validationPath = './trainingDataset/test/'\n",
        "\n",
        "#Training Path\n",
        "Train_chairPath = \"./trainingDataset/train/chair\"\n",
        "trainChairPose = os.listdir(Train_chairPath)\n",
        "print('total Chair Pose Images', len(trainChairPose))\n",
        "Train_cobraPath = \"./trainingDataset/train/cobra\"\n",
        "trainCobraPose = os.listdir(Train_cobraPath)\n",
        "print('total cobra Pose Images', len(trainCobraPose))\n",
        "train_dogPath = \"./trainingDataset/train/dog\"\n",
        "trainDogPose = os.listdir(train_dogPath)\n",
        "print('total dog Pose Images', len(trainDogPose))\n",
        "train_treePath = \"./trainingDataset/train/tree\"\n",
        "trainTreePose = os.listdir(train_treePath)\n",
        "print('total tree Pose Images', len(trainTreePose))\n",
        "train_warriorPath = \"./trainingDataset/train/warrior\"\n",
        "trainWarriorPose = os.listdir(train_warriorPath)\n",
        "print('total warrior Pose Images', len(trainWarriorPose))\n",
        "\n",
        "#Testing or Validation Path\n",
        "Validation_chairPath = \"./trainingDataset/train/chair\"\n",
        "validationChairPose = os.listdir(Validation_chairPath)\n",
        "print('total Chair Pose Images', len(validationChairPose))\n",
        "Validation_cobraPath = \"./trainingDataset/train/cobra\"\n",
        "validationCobraPose = os.listdir(Validation_cobraPath)\n",
        "print('total cobra Pose Images', len(validationCobraPose))\n",
        "Validation_dogPath = \"./trainingDataset/train/dog\"\n",
        "validationDogPose = os.listdir(Validation_dogPath)\n",
        "print('total dog Pose Images', len(validationDogPose))\n",
        "Validation_treePath = \"./trainingDataset/train/tree\"\n",
        "validationTreePose = os.listdir(Validation_treePath)\n",
        "print('total tree Pose Images', len(validationTreePose))\n",
        "Validation_warriorPath = \"./trainingDataset/train/warrior\"\n",
        "trainWarriorPose = os.listdir(Validation_warriorPath)\n",
        "print('total warrior Pose Images', len(trainWarriorPose))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e37ffd1",
      "metadata": {
        "id": "5e37ffd1"
      },
      "source": [
        "### Visualizing dataset using data matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727d4f0c",
      "metadata": {
        "id": "727d4f0c"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plot\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "#view it as 5x5\n",
        "Visrows = 5\n",
        "Viscols = 5\n",
        "picIndex = 0 #starts index from 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b44d413",
      "metadata": {
        "id": "4b44d413"
      },
      "outputs": [],
      "source": [
        "#view dataset images by using matplotlib\n",
        "figure = plot.gcf()\n",
        "figure.set_size_inches(Visrows * 5, Viscols * 5)\n",
        "#add index +10 because we are going through 10 photos now\n",
        "picIndex += 10\n",
        "# view all classification of the pose\n",
        "\"\"\"\n",
        "Chair\n",
        "Cobra\n",
        "Dog\n",
        "Tree\n",
        "Warrior\n",
        "\n",
        "#Training Path\n",
        "Train_chairPath = \"./trainingDataset/train/chair\"\n",
        "trainChairPose = os.listdir(Train_chairPath)\n",
        "print('total Chair Pose Images', len(trainChairPose))\n",
        "Train_cobraPath = \"./trainingDataset/train/cobra\"\n",
        "trainCobraPose = os.listdir(Train_cobraPath)\n",
        "print('total cobra Pose Images', len(trainCobraPose))\n",
        "train_dogPath = \"./trainingDataset/train/dog\"\n",
        "trainDogPose = os.listdir(train_dogPath)\n",
        "print('total dog Pose Images', len(trainDogPose))\n",
        "train_treePath = \"./trainingDataset/train/tree\"\n",
        "trainTreePose = os.listdir(train_treePath)\n",
        "print('total tree Pose Images', len(trainTreePose))\n",
        "train_warriorPath = \"./trainingDataset/train/warrior\"\n",
        "trainWarriorPose = os.listdir(train_warriorPath)\n",
        "print('total warrior Pose Images', len(trainWarriorPose))\n",
        "\"\"\"\n",
        "\n",
        "seekChairData = [os.path.join(Train_chairPath, fname) for fname in trainChairPose[picIndex-10:picIndex]]\n",
        "seekCobraData = [os.path.join(Train_cobraPath, fname) for fname in trainCobraPose[picIndex-10:picIndex]]\n",
        "seekDogData = [os.path.join(train_dogPath, fname) for fname in trainDogPose[picIndex-10:picIndex]]\n",
        "seekTreeData = [os.path.join(train_treePath, fname) for fname in trainTreePose[picIndex-10:picIndex]] \n",
        "seekWarriorData = [os.path.join(train_warriorPath, fname) for fname in trainWarriorPose[picIndex-10:picIndex]] \n",
        "\n",
        "for a, imPath in enumerate(seekChairData + seekCobraData + seekDogData + seekTreeData + seekWarriorData):\n",
        "  subPlot = plot.subplot(Visrows, Viscols, a + 1)\n",
        "  subPlot.axis('On') #i wanna see the axis and the gridline\n",
        "  image = mpimg.imread(imPath)\n",
        "  plot.imshow(image)\n",
        "plot.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0abbc54",
      "metadata": {
        "id": "e0abbc54"
      },
      "source": [
        "### data resizing and classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f077b4b0",
      "metadata": {
        "id": "f077b4b0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as dataGen\n",
        "\n",
        "#lets target the scaling res\n",
        "#rescaling 244 244\n",
        "trainDatagen = dataGen(rescale=1/255) #1/255\n",
        "validationDatagen = dataGen(rescale=1/255) #1/255\n",
        "\"\"\"\n",
        "Chair\n",
        "Cobra\n",
        "Dog\n",
        "Tree\n",
        "Warrior\n",
        "\"\"\"\n",
        "trainDataGenerator = trainDatagen.flow_from_directory(\n",
        "    trainingPath,\n",
        "    classes = ['chair', 'cobra', 'dog', 'tree', 'warrior'],\n",
        "    target_size = (244, 244),\n",
        "    batch_size = 120,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "trainingValidationGenerator = validationDatagen.flow_from_directory(\n",
        "    validationPath,\n",
        "    classes = ['chair', 'cobra', 'dog', 'tree', 'warrior'],\n",
        "    target_size = (244, 244),\n",
        "    batch_size = 8,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ddb948b",
      "metadata": {
        "id": "1ddb948b"
      },
      "source": [
        "# Train time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119a3528",
      "metadata": {
        "id": "119a3528"
      },
      "outputs": [],
      "source": [
        "history = model.fit(trainDataGenerator,\n",
        "steps_per_epoch=8,\n",
        "epochs=16,\n",
        "verbose=1,\n",
        "validation_data = trainingValidationGenerator,\n",
        "validation_steps=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Model h5 and tflite"
      ],
      "metadata": {
        "id": "9jYPoktvQX3O"
      },
      "id": "9jYPoktvQX3O"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(trainingValidationGenerator)"
      ],
      "metadata": {
        "id": "GxETRc4NQXbl"
      },
      "id": "GxETRc4NQXbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('motionful_prealpha.h5')"
      ],
      "metadata": {
        "id": "BUXCvBm7RdA5"
      },
      "id": "BUXCvBm7RdA5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "metadata": {
        "id": "cyrTS4QiSB24"
      },
      "id": "cyrTS4QiSB24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### converting h5 to tflite"
      ],
      "metadata": {
        "id": "bEAPdLyiSP0M"
      },
      "id": "bEAPdLyiSP0M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the classificaiton\n",
        "! echo \"chair\" > motionful_prealpha_classification.txt\n",
        "! echo \"cobra\" >> motionful_prealpha_classification.txt\n",
        "! echo \"dog\" >> motionful_prealpha_classification.txt\n",
        "! echo \"tree\" >> motionful_prealpha_classification.txt\n",
        "! echo \"warrior\" >> motionful_prealpha_classification.txt"
      ],
      "metadata": {
        "id": "l5X7CbV1TVGV"
      },
      "id": "l5X7CbV1TVGV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLoad = tf.keras.models.load_model('motionful_prealpha.h5')\n",
        "converterModel = tf.lite.TFLiteConverter.from_keras_model(modelLoad)\n",
        "tfLiteModelExport = converterModel.convert()\n",
        "open(\"motionful_prealpha.tflite\", \"wb\").write(tfLiteModelExport)"
      ],
      "metadata": {
        "id": "zokfDDD5SC5H"
      },
      "id": "zokfDDD5SC5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download zip archive the model"
      ],
      "metadata": {
        "id": "mbZCS1JATD0e"
      },
      "id": "mbZCS1JATD0e"
    },
    {
      "cell_type": "code",
      "source": [
        "import files\n",
        "files.download('motionful_prealpha.tflite')\n",
        "files.download('motionful_prealpha.h5')\n",
        "files.download('motionful_prealpha_classification.txt')"
      ],
      "metadata": {
        "id": "N5ArWt0WTBhv"
      },
      "id": "N5ArWt0WTBhv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "TrainMobileNetv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}